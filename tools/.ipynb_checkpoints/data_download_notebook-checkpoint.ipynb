{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 14:11:46.082239: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-16 14:11:46.141902: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-16 14:11:46.142676: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-16 14:11:48.887865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import io\n",
    "\n",
    "import matplotlib.patches\n",
    "\n",
    "from IPython.display import HTML as html_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_to_rgb(seg, palette=None, num_objects=None, bg_color=(0, 0, 0)):\n",
    "  if num_objects is None:\n",
    "    num_objects = np.max(seg)  # assume consecutive numbering\n",
    "  num_objects += 1  # background\n",
    "  if palette is None:\n",
    "    palette = [bg_color] + sns.color_palette('hls', num_objects-1)\n",
    "\n",
    "  seg_img = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.float32)\n",
    "  for i in range(num_objects):\n",
    "    seg_img[np.nonzero(seg[:, :, 0] == i)] = palette[i]\n",
    "  return seg_img\n",
    "\n",
    "def depth_to_rgb(depth, colormap=matplotlib.cm.viridis_r, sqrt=True):\n",
    "  cmap = np.array(colormap.colors)\n",
    "  if sqrt:\n",
    "    d = np.round(np.sqrt((depth[..., 0] / 65535).clip(0, 1.)) * 255).astype(np.uint8)\n",
    "  else:\n",
    "    d = np.round(depth[..., 0] // 256).astype(np.uint8)\n",
    "  return cmap[d]\n",
    "\n",
    "def flow_to_rgb(vec, flow_mag_range=None, white_bg=False):\n",
    "  height, width = vec.shape[:2]\n",
    "  scaling = 50. / (height**2 + width**2)**0.5\n",
    "  direction = (np.arctan2(vec[..., 0], vec[..., 1]) + np.pi) / (2 * np.pi)\n",
    "  norm = np.linalg.norm(vec, axis=-1)\n",
    "  if flow_mag_range is None:\n",
    "    flow_mag_range = norm.min(), norm.max()\n",
    "  magnitude = np.clip((norm - flow_mag_range[0]) * scaling, 0., 1.)\n",
    "  if white_bg == True:\n",
    "    value = np.ones_like(direction)\n",
    "    hsv = np.stack([direction, magnitude, saturation], axis=-1)\n",
    "  else:\n",
    "    saturation = np.ones_like(direction)\n",
    "    hsv = np.stack([direction, saturation , magnitude], axis=-1)\n",
    "  rgb = matplotlib.colors.hsv_to_rgb(hsv)\n",
    "  return rgb\n",
    "\n",
    "def plot_bboxes(sample, palette=None, linewidth=1):\n",
    "  resolution = sample[\"video\"].shape[-3:-1]\n",
    "\n",
    "  bboxes = sample[\"instances\"][\"bboxes\"]\n",
    "  bbox_frames = sample[\"instances\"][\"bbox_frames\"]\n",
    "  num_objects = bboxes.shape[0]\n",
    "  if palette is None:\n",
    "      palette = sns.color_palette('hls', num_objects)\n",
    "  images = []\n",
    "  for t, rgb in enumerate(sample[\"video\"]):\n",
    "    fig, ax = plt.subplots(figsize=(resolution[0]/100, resolution[1]/100), dpi=132.5)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(rgb)\n",
    "    for k in range(num_objects):\n",
    "      if t in bbox_frames[k]:\n",
    "        idx = np.nonzero(bbox_frames[k] == t)[0][0]\n",
    "\n",
    "        miny, minx, maxy, maxx = bboxes[k][idx]\n",
    "        miny = max(1, miny*resolution[0])\n",
    "        minx = max(1, minx*resolution[1])\n",
    "        maxy = min(resolution[0]-1, maxy*resolution[0])\n",
    "        maxx = min(resolution[1]-1, maxx*resolution[1])\n",
    "        rect = matplotlib.patches.Rectangle([minx, miny], maxx-minx, maxy-miny,\n",
    "                                            linewidth=linewidth, edgecolor=palette[k],\n",
    "                                            facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "\n",
    "    for k in range(num_objects):\n",
    "      x, y = sample[\"instances\"][\"image_positions\"][k, t] * resolution\n",
    "      if np.all(1 < y < resolution[0]-1) and np.all(1 < x < resolution[1]-1):\n",
    "        ax.scatter(x, y, marker=\"X\", s=5, color=palette[k])\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format = \"png\", bbox_inches = 'tight', pad_inches = 0, dpi=132.5)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    img = PIL.Image.open(buf)\n",
    "    images.append(np.array(img)[..., :3])\n",
    "  return images\n",
    "\n",
    "def getsize(arr): \n",
    "  if isinstance(arr, np.ndarray):\n",
    "    return arr.nbytes\n",
    "  elif isinstance(arr, dict):\n",
    "    return sum([getsize(v) for v in arr.values()])\n",
    "  elif isinstance(arr, list):\n",
    "    return sum([getsize(v) for v in arr])\n",
    "  else:\n",
    "    return sys.getsizeof(arr)\n",
    "\n",
    "def print_instance_ids(sample, ds_info, palette=None):\n",
    "  if palette is None:\n",
    "    palette = sns.color_palette('hls', sample[\"metadata\"][\"num_instances\"])\n",
    "  out = ''\n",
    "  if \"asset_id\" in sample[\"instances\"]:\n",
    "    ids = [s.decode() for s in sample[\"instances\"][\"asset_id\"]]\n",
    "  else:\n",
    "    labels = []\n",
    "    if \"size_label\" in sample[\"instances\"]:\n",
    "      labels.append([ds_info.features[\"instances\"][\"size_label\"].names[k]\n",
    "                       for k in sample[\"instances\"][\"size_label\"]])\n",
    "    if \"color_label\" in sample[\"instances\"]:\n",
    "      labels.append([ds_info.features[\"instances\"][\"color_label\"].names[k]\n",
    "                       for k in sample[\"instances\"][\"color_label\"]])\n",
    "    labels.append([ds_info.features[\"instances\"][\"material_label\"].names[k]\n",
    "                       for k in sample[\"instances\"][\"material_label\"]])\n",
    "    labels.append([ds_info.features[\"instances\"][\"shape_label\"].names[k]\n",
    "                   for k in sample[\"instances\"][\"shape_label\"]])\n",
    "    ids = [\" \".join(x) for x in zip(*labels)]\n",
    "\n",
    "  for i, (color, asset_id) in enumerate(zip(palette, ids)):\n",
    "    color_hex = '#%02x%02x%02x' % tuple(int(x*255) for x in color)\n",
    "    out += f'{i}. <b><text style=color:{color_hex}>{asset_id}</text></b><br/>'\n",
    "    \n",
    "  return html_print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 14:12:40.816182: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint16'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint16.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
      "2023-06-16 14:12:45.325065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-16 14:12:45.326581: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    }
   ],
   "source": [
    "ds, ds_info = tfds.load(\"movi_e\", data_dir=\"gs://kubric-public/tfds\", with_info=True)\n",
    "train_iter = iter(tfds.as_numpy(ds[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(train_iter)\n",
    "minv, maxv = example[\"metadata\"][\"forward_flow_range\"]\n",
    "forward_flow = example[\"forward_flow\"] / 65535 * (maxv - minv) + minv\n",
    "\n",
    "minv, maxv = example[\"metadata\"][\"backward_flow_range\"]\n",
    "backward_flow = example[\"backward_flow\"] / 65535 * (maxv - minv) + minv\n",
    "\n",
    "minv, maxv = example[\"metadata\"][\"depth_range\"]\n",
    "depth = example[\"depth\"] / 65535 * (maxv - minv) + minv\n",
    "\n",
    "media.show_videos({\"rgb\": example[\"video\"], \n",
    "                   \"segmentation\": [segmentation_to_rgb(s, num_objects=example[\"metadata\"][\"num_instances\"])\n",
    "                                    for s in example[\"segmentations\"]],\n",
    "                   \"depth\": depth_to_rgb(example[\"depth\"], sqrt=True),\n",
    "                   \"normal\": example[\"normal\"],\n",
    "                   \"forward_flow\": flow_to_rgb(forward_flow, white_bg=False),\n",
    "                   \"backward_flow\": flow_to_rgb(backward_flow, white_bg=False),\n",
    "                   \"object_coordinates\": example[\"object_coordinates\"], \n",
    "                   \"bboxes/center_of_mass\": plot_bboxes(example),\n",
    "                   },\n",
    "                fps=12,\n",
    "                columns=4,\n",
    "                codec=\"gif\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
